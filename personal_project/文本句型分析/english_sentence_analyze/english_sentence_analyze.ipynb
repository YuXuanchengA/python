{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# 分句\n",
    "def sents_tokenize(content):\n",
    "    sent_tokenize_list = sent_tokenize(content)\n",
    "    return sent_tokenize_list\n",
    "\n",
    "def sents_analyze(sents):\n",
    "    sents_pattern = []\n",
    "    i = 0\n",
    "    for sent in sents:\n",
    "        i += 1\n",
    "        # 分词\n",
    "        words = sent.lower() #全部转换为小写\n",
    "        words = word_tokenize(words)\n",
    "        word_l = []\n",
    "        for w in words:\n",
    "            word_l.append(w)\n",
    "        #print(word_l)\n",
    "        # 词性标注\n",
    "        # pos = nltk.pos_tag(words)\n",
    "        # 判断\n",
    "        \n",
    "        #compound sentence or complex sentence\n",
    "        if ('because' in word_l):\n",
    "            sents_pattern.append('原因状语从句')\n",
    "        elif ('and' in word_l) or ('or' in word_l ) or ('but' in word_l):\n",
    "            sents_pattern.append('并列句')\n",
    "        elif ('if' in word_l) or ('unless' in word_l):\n",
    "            sents_pattern.append('条件状语从句')\n",
    "        elif ('though' in word_l) or ('although' in word_l):\n",
    "            sents_pattern.append('让步状语从句')\n",
    "        elif word_l[-1] == '!' :\n",
    "            sents_pattern.append('感叹句')\n",
    "        elif word_l[-1] == '?' :\n",
    "            sents_pattern.append('疑问句')\n",
    "            \n",
    "        # 其他\n",
    "        else:\n",
    "            sents_pattern.append('陈述句')\n",
    "        \n",
    "        if i == 5000:\n",
    "            break\n",
    "    return sents_pattern\n",
    "            \n",
    "#main\n",
    "with open('Pullman, Philip - His Dark Materials, Book 2.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read().replace('\\n', '')\n",
    "    # 去除对话引号，不影响判断\n",
    "    content = content.replace('\"', '')\n",
    "    \n",
    "sents = sents_tokenize(content)\n",
    "patterns = sents_analyze(sents)\n",
    "with open('Pullman, Philip - His Dark Materials, Book 2_analyze.txt', 'w', encoding='utf-8') as f:\n",
    "    for pattern, sent in zip(patterns,sents):\n",
    "        f.write('{}\\t{}\\n'.format(pattern, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准确率判断\n",
    "import random\n",
    "test = []\n",
    "test_pattern = []\n",
    "test_sent = []\n",
    "\n",
    "for i in range(200) :\n",
    "    num = random.randint(0,4999) # 闭区间\n",
    "    if(num not in test):\n",
    "        test.append(num)\n",
    "        test_pattern.append(patterns[num])\n",
    "        test_sent.append(sents[num])\n",
    "\n",
    "# 将抽取的200个句子存入文件            \n",
    "with open('measurement_english.txt', 'w', encoding='utf-8') as f: \n",
    "    for pattern, sent in zip(test_pattern,test_sent):\n",
    "        f.write('{}\\t{}\\n'.format(pattern, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人工判断准确率\n",
    "# 错误个数：并列句：23；感叹句：1\n",
    "# 准确率：76%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
